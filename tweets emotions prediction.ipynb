{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ff3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.models import Phrases\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0b3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"full-corpus-training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9429671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Sentiment\"] != \"irrelevant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc7632a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849754a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>437</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2228</td>\n",
       "      <td>2228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TweetId  TweetText\n",
       "Sentiment                    \n",
       "negative       437        437\n",
       "neutral       2228       2228\n",
       "positive       329        329"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bd4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_colos(data): # for each docment we will add collocaions of biagrams and triagrams. Like if we have red and wine frequently appeqaring together, we will add red_wine as single word to the document\n",
    "    text_clean= [data]\n",
    "    \n",
    "    bigram = Phrases(text_clean)\n",
    "    trigram = Phrases(bigram[text_clean])\n",
    "\n",
    "    for idx in range(len(text_clean)):\n",
    "        for token in bigram[text_clean[idx]]:\n",
    "            if '_' in token:\n",
    "                text_clean[idx].append(token)\n",
    "        for token in trigram[text_clean[idx]]:           \n",
    "            if '_' in token:\n",
    "                text_clean[idx].append(token)\n",
    "                \n",
    "    return text_clean[0]\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "493963f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf5d93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_preprocess(raw): # biagrmas?\n",
    "    raw = re.sub(r\"http://(?:[^/]+/)*.*\",\"\",raw).strip()\n",
    "    raw = re.sub(r\"\\d+\",\"\",raw).strip()\n",
    "    new = \"\"\n",
    "    for i in raw:\n",
    "        new = new+i if i not in string.punctuation else new\n",
    "        \n",
    "    new = list(map(lambda x : x.lower(), new.split()))\n",
    "    \n",
    "    new = [word for word in new if word not in stopwords]\n",
    "    new = [word for word in new if word]\n",
    "    \n",
    "    new = add_colos(new)\n",
    "    \n",
    "    lemmas = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in new]\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f402be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"TweetText\"]], df[\"Sentiment\"], test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdfab5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([X_train,y_train],axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f007db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TweetText\n",
       "Sentiment           \n",
       "negative         364\n",
       "neutral         1896\n",
       "positive         284"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853b533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_neutral = t[t.Sentiment!=\"neutral\"]\n",
    "neutral = t[t.Sentiment==\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9728c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_upsampled = resample(not_neutral,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(neutral), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "\n",
    "upsampled = pd.concat([neutral_upsampled, neutral])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865530fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_downsampled = resample(neutral,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(not_neutral), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([neutral_downsampled, not_neutral])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33c23cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TweetText\n",
       "Sentiment           \n",
       "negative        1057\n",
       "neutral         1896\n",
       "positive         839"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled.groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e599cda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TweetText\n",
       "Sentiment           \n",
       "negative         364\n",
       "neutral          648\n",
       "positive         284"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled.groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "68ec7e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiple_classifiers(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self, clasis):\n",
    "        self.pipes = clasis\n",
    "        \n",
    "        \n",
    "    def fit(self,classes,x):\n",
    "        for i in range(len(classes)-1):\n",
    "            for j in range(i+1, len(classes)):\n",
    "                one = x[x['Sentiment'] == classes[i]]\n",
    "                two = x[x['Sentiment'] == classes[j]]\n",
    "                new = pd.concat([one,two])\n",
    "                new.reset_index(inplace = True)\n",
    "                self.pipes[i+j-1].fit(new[\"TweetText\"],new[\"Sentiment\"]) \n",
    "        return \n",
    "        \n",
    "    def predict(self,matrix):\n",
    "        preds = []\n",
    "        for i in range(len(matrix)):\n",
    "            row = matrix.loc[[i], [\"TweetText\"]]\n",
    "            cur = []        \n",
    "            for pipe in self.pipes:\n",
    "                cur.append(pipe.predict(row)[0])\n",
    "            #print(cur)\n",
    "            champion =  sorted(cur, key = lambda y : cur.count(y),reverse = True)[0]\n",
    "            preds.append(champion)\n",
    "        #print(\"Done predicting\")\n",
    "        return preds\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"something\"\n",
    "    def __str__(self):\n",
    "        return f\"model: {self.pipes[0].steps[-1][0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef626975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_t(actual, preds):\n",
    "    scores = accuracy_score(y_test,preds)\n",
    "    scores1 = precision_score(y_test,preds,average=\"weighted\")\n",
    "    scores2 =  recall_score(y_test,preds,average=\"weighted\")\n",
    "    scores3 =  f1_score(y_test,preds,average=\"weighted\")\n",
    "    print(scores,scores1,scores2,scores3)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "12f800e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(set((df[\"Sentiment\"])))\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "770e4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classifiers = int(math.factorial(m)/(2* math.factorial(m-n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "116ed9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipes(n,choice = \"log\"):\n",
    "    res= []\n",
    "    for i in range(n):\n",
    "        if choice == \"log\":\n",
    "            res.append(Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=lambda x : text_preprocess(x))), (\"LogisticRegression\",  LogisticRegression())]))\n",
    "        elif choice == \"sgd\":\n",
    "            res.append(Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=lambda x : text_preprocess(x))), (\"SGDClassifier\",  SGDClassifier())]))\n",
    "        elif choice == \"svm\":\n",
    "            res.append(Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=lambda x : text_preprocess(x))), (\"svm.SVC\",  svm.SVC(kernel='rbf',random_state=0))]))\n",
    "        else:\n",
    "            res.append(Pipeline([(\"vectorizer\", TfidfVectorizer(tokenizer=lambda x : text_preprocess(x))), (\"random forest\", RandomForestClassifier())]))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "3a7a101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = create_pipes(number_of_classifiers)\n",
    "p2 = create_pipes(number_of_classifiers,\"sgd\")\n",
    "p3 = create_pipes(number_of_classifiers,\"svm\")\n",
    "p4 = create_pipes(number_of_classifiers,\"forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a4ee8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes1 = multiple_classifiers(p1)\n",
    "pipes2 = multiple_classifiers(p2)\n",
    "pipes3 = multiple_classifiers(p3)\n",
    "pipes4 = multiple_classifiers(p4)\n",
    "\n",
    "lst = [pipes1,pipes2,pipes3,pipes4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "51cde6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_analyse(pipes,x,x_test,y_test):\n",
    "    for pipe in pipes:\n",
    "        pipe.fit(list(set(x[\"Sentiment\"])),x)\n",
    "        \n",
    "    for pipe in pipes:\n",
    "        preds = pipe.predict(x_test.reset_index(drop=True))\n",
    "        print(pipe)\n",
    "        see_t(y_test,preds)\n",
    "        print()\n",
    "    return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "bd938b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LogisticRegression\n",
      "0.7377777777777778 0.544316049382716 0.7377777777777778 0.6264506962205173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: SGDClassifier\n",
      "0.7377777777777778 0.544316049382716 0.7377777777777778 0.6264506962205173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: svm.SVC\n",
      "0.7377777777777778 0.544316049382716 0.7377777777777778 0.6264506962205173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: random forest\n",
      "0.7377777777777778 0.544316049382716 0.7377777777777778 0.6264506962205173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_analyse(lst,downsampled,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a01d1da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LogisticRegression\n",
      "0.7377777777777778 0.544316049382716 0.7377777777777778 0.6264506962205173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: SGDClassifier\n",
      "0.7377777777777778 0.544316049382716 0.7377777777777778 0.6264506962205173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: svm.SVC\n",
      "0.7377777777777778 0.544316049382716 0.7377777777777778 0.6264506962205173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: random forest\n",
      "0.1 0.01 0.1 0.01818181818181818\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_analyse(lst,upsampled,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc510278",
   "metadata": {},
   "outputs": [],
   "source": [
    "class to_sparse(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,vec):\n",
    "        self.vec = vec\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        self.vec.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        return self.vec.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "9b5ce303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5222222222222223 0.6947611921037475 0.5222222222222223 0.5654530635531919\n"
     ]
    }
   ],
   "source": [
    "ct = to_sparse(TfidfVectorizer(tokenizer=lambda x : text_preprocess(x)))\n",
    "\n",
    "baes = Pipeline([(\"vectorizer\", ct), (\"GaussianNB\",  GaussianNB())])\n",
    "\n",
    "baes.fit(downsampled[\"TweetText\"],downsampled[\"Sentiment\"])\n",
    "\n",
    "preds = baes.predict(X_test[\"TweetText\"])\n",
    "\n",
    "see_t(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "bf1eaff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62 0.6676357886809434 0.62 0.6392088664219812\n"
     ]
    }
   ],
   "source": [
    "ct = to_sparse(TfidfVectorizer(tokenizer=lambda x : text_preprocess(x)))\n",
    "\n",
    "baes = Pipeline([(\"vectorizer\", ct), (\"GaussianNB\",  GaussianNB())])\n",
    "\n",
    "baes.fit(X_train[\"TweetText\"],y_train)\n",
    "\n",
    "preds = baes.predict(X_test[\"TweetText\"])\n",
    "\n",
    "see_t(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4da2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7933333333333333 0.7905072254208622 0.7933333333333333 0.7517478428004744\n"
     ]
    }
   ],
   "source": [
    "ct = to_sparse(TfidfVectorizer(tokenizer=lambda x : text_preprocess(x)))\n",
    "forest = Pipeline([(\"vectorizer\", ct), (\"GaussianNB\",  RandomForestClassifier())])\n",
    "forest.fit(X_train[\"TweetText\"],y_train)\n",
    "preds3 = forest.predict(X_test[\"TweetText\"])\n",
    "\n",
    "see_t(y_test,preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "a27fa874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7377777777777778 0.544316049382716 0.7377777777777778 0.6264506962205173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipes1.fit(list(set(t[\"Sentiment\"])),t)\n",
    "preds1 = pipes1.predict(X_test.reset_index(drop=True))\n",
    "see_t(y_test,preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d278f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "353cf3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = pd.read_excel(\"testing_data.xlsx\",header=None,names = [\"id\",\"TweetText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "07853790",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = baes.predict(to_predict[\"TweetText\"])\n",
    "result_df = pd.DataFrame({\"Tweets\":result})\n",
    "result_df.to_excel(\"C://Users/La_Admin/Desktop/out_w3.xlsx\",encoding=\"UTF-8\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "fb4d6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pipes1.predict(to_predict[[\"TweetText\"]])\n",
    "result_df1 = pd.DataFrame({\"Tweets\":result1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a41f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "ae6ffe45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "ee312f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "9fce983a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New macbook is too sick @apple'"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict[\"TweetText\"][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c54f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
